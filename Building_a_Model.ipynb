{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building a Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcHnhke+As5yzisKk5kTJ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashindustry007/Code-References-and-Boilerplates---DL/blob/main/Building_a_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByrKGVCPtX2-"
      },
      "source": [
        "**Models API**\n",
        "\n",
        "There are three ways to create Keras models:\n",
        "\n",
        "* The Sequential model, which is very straightforward (a simple list of layers), but is limited to single-input, single-output stacks of layers (as the name gives away).\n",
        "\n",
        "* The Functional API, which is an easy-to-use, fully-featured API that supports arbitrary model architectures. For most people and most use cases, this is what you should be using. This is the Keras \"industry strength\" model.\n",
        "\n",
        "* Model subclassing, where you implement everything from scratch on your own. Use this if you have complex, out-of-the-box research use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PflCNS85ujR4"
      },
      "source": [
        "https://keras.io/api/models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zezpVHsu0Dq"
      },
      "source": [
        "##Keras - Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_QeYyP3tJZI"
      },
      "source": [
        "#Creating by passing a list of layers to the sequential constructor. \n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(2, activation=\"relu\"),\n",
        "        layers.Dense(3, activation=\"relu\"),\n",
        "        layers.Dense(4),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMjICPHuvlwl"
      },
      "source": [
        "#Creating a sequential model incrementally via the add() method.\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(2, activation=\"relu\"))\n",
        "model.add(layers.Dense(3, activation=\"relu\"))\n",
        "model.add(layers.Dense(4))\n",
        "\n",
        "#add to a model is like append to a list."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfHnR21O0oYl"
      },
      "source": [
        "#pop method to remove model layer. Sequential model acts very much like a python list.\n",
        "model.pop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTZLNUEwwOJT"
      },
      "source": [
        "#it accepts name argument\n",
        "model = keras.Sequential(name=\"my_sequential\")\n",
        "model.add(keras.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n",
        "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTiDyPNu14At"
      },
      "source": [
        "Parallel Computing With Multiple GPUs\n",
        "\n",
        "https://colab.research.google.com/github/keras-team/keras-io/blob/master/guides/ipynb/distributed_training.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptGYDer21TrI"
      },
      "source": [
        "Feature extraction\n",
        "\n",
        "Once a sequential model is built, it behaves like a Functional API model. So every layer has it's own input and output attribute. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB3OlJJe053N"
      },
      "source": [
        "initial_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(250, 250, 3)),\n",
        "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "#extracting feature from only one layer\n",
        "feature_extractor = keras.Model(\n",
        "    inputs=initial_model.inputs,\n",
        "    outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output,\n",
        ")\n",
        "\n",
        "#extracting feature from all the intermediate layers\n",
        "feature_extractor = keras.Model(\n",
        "    inputs=initial_model.inputs,\n",
        "    outputs=[layer.output for layer in initial_model.layers],\n",
        ")\n",
        "\n",
        "# Call feature extractor on test input.\n",
        "x = tf.ones((1, 250, 250, 3))\n",
        "features = feature_extractor(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq8Bd0slFfxl"
      },
      "source": [
        "Transfer Learning\n",
        "\n",
        "Transfer learning consists of freezing the bottom layers in a model and only training the top layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1G1CcF0FgG0"
      },
      "source": [
        "# Load a convolutional base with pre-trained weights\n",
        "base_model = keras.applications.Xception(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    pooling='avg')\n",
        "\n",
        "# 1st way\n",
        "# Freeze all layers except the last one.\n",
        "for layer in base_model.layers[:-1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# 2nd way\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "# Use a Sequential model to add a trainable classifier on top\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.Dense(1000),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkT-mhZVMoHU"
      },
      "source": [
        "##Keras - Functional Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPquZUdxStJf"
      },
      "source": [
        "The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_e5wVWxSPC-"
      },
      "source": [
        "# initializing a graph network with 3 layers\n",
        "# (input: 784-dimensional vectors) ↧ [Dense (64 units, relu activation)] ↧ [Dense (64 units, relu activation)] ↧ [Dense (10 units, softmax activation)] ↧ (output: logits of a probability distribution over 10 classes)\n",
        "\n",
        "# 1st step - creating input node\n",
        "inputs = keras.Input(shape=(784,)) #for normal inputs\n",
        "img_inputs = keras.Input(shape=(32, 32, 3)) #for image inputs, just an example. Not to be included in this code.\n",
        "\n",
        "# 2nd step - creating the layers in-between\n",
        "x = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "# 3rd step - creating the last output layer\n",
        "outputs = layers.Dense(10)(x)\n",
        "\n",
        "# Last step involves creating model by specifying its input and outputs in the graph of layers\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"name_of_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzUfu43WhIRK"
      },
      "source": [
        "# To visualise the model architecture\n",
        "model.summary() #first type\n",
        "keras.utils.plot_model(model, \"name.png\") #second type\n",
        "keras.utils.plot_model(model, \"name.png\", show_shapes=True) #third type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSvy09gZnPj-"
      },
      "source": [
        "# example with an end-to-end auto-encoder model\n",
        "\n",
        "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
        "encoder_output = layers.GlobalMaxPooling2D()(x) #16 as output\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
        "x = layers.Reshape((4, 4, 1))(encoder_output)\n",
        "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
        "x = layers.UpSampling2D(3)(x)\n",
        "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x) #28, 28, 1 as output\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "# You can treat any model as if it were a layer by invoking it on an Input or on the output of another layer. \n",
        "# By calling a model you aren't just reusing the architecture of the model, you're also reusing its weights.\n",
        "\n",
        "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
        "autoencoder.summary()\n",
        "\n",
        "# Decoding architecture is strictly symmetrical to the encoding architecture, hence input shape is equal to output shape.\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}